{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmQjvkPedrMv",
        "outputId": "1fff7516-c0cc-4d4d-e5a3-9a72de4ec857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.28.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.28.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.1.31)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxBVASQMeRaH",
        "outputId": "10a812ff-7800-4b20-da05-2a214f8804e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Connecting to cloud.r-project.org (108.139.1\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Connected to cloud.r-project.org (108.139.15.85)] [Connected to r2u.stat.i\r                                                                                                    \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-browser is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y chromium-browser\n",
        "!apt install chromium-chromedriver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "7T-hH5sadvNl"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxRTBPrGf2fv",
        "outputId": "4b197e95-86d6-40b1-bc61-d5c2a0438648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chromedriver\n"
          ]
        }
      ],
      "source": [
        "!ls /usr/lib/chromium-browser/chromedriver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "xqaWwBaCQ9TB"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "email= userdata.get('email')\n",
        "password= userdata.get('password')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "rGLVNce_d3h0"
      },
      "outputs": [],
      "source": [
        "url= 'https://archiveofourown.org/users/Sw33tBl0550m/readings'\n",
        "\n",
        "def web_driver():\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument(\"--verbose\")\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--disable-gpu')\n",
        "    options.add_argument(\"--window-size=1920, 1200\")\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    return driver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "Fu5wDHhAhlYu"
      },
      "outputs": [],
      "source": [
        "driver = web_driver()\n",
        "driver.get(url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "7qt7r5l1hzdp"
      },
      "outputs": [],
      "source": [
        "driver.find_element(By.XPATH, '//*[@id=\"user_login\"]').send_keys(email)\n",
        "driver.find_element(By.XPATH, '//*[@id=\"user_password\"]').send_keys(password)\n",
        "driver.find_element(By.XPATH, '//*[@id=\"new_user\"]/dl/dd[4]/input').click()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35-GghkQnSzI",
        "outputId": "88a40284-cbaa-44b2-ce00-37bf31d099e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraping page 1\n",
            "Found 20 titles on this page\n",
            "Found 20 authors on this page\n",
            "Found 20 fandom tags on this page\n",
            "Found 20 relationship tags on this page\n",
            "Found 20 character tags on this page\n",
            "Found 20 character tags on this page\n",
            "Found summaries on this page\n",
            "Found words on this page\n",
            "Found chapter on this page\n",
            "Found next button, attempting to click\n",
            "Clicked next button\n",
            "Successfully moved to page 2\n",
            "Scraping page 2\n",
            "Found 20 titles on this page\n",
            "Found 40 authors on this page\n",
            "Found 40 fandom tags on this page\n",
            "Found 40 relationship tags on this page\n",
            "Found 40 character tags on this page\n",
            "Found 40 character tags on this page\n",
            "Found summaries on this page\n",
            "Found words on this page\n",
            "Found chapter on this page\n",
            "Found next button, attempting to click\n",
            "Clicked next button\n",
            "Successfully moved to page 3\n",
            "Scraping page 3\n",
            "Found 20 titles on this page\n",
            "Found 60 authors on this page\n",
            "Found 60 fandom tags on this page\n",
            "Found 60 relationship tags on this page\n",
            "Found 60 character tags on this page\n",
            "Found 60 character tags on this page\n",
            "Found summaries on this page\n",
            "Found words on this page\n",
            "Found chapter on this page\n",
            "Found next button, attempting to click\n",
            "Clicked next button\n",
            "Successfully moved to page 4\n",
            "Scraping page 4\n",
            "Found 20 titles on this page\n",
            "Found 80 authors on this page\n",
            "Found 80 fandom tags on this page\n",
            "Found 80 relationship tags on this page\n",
            "Found 80 character tags on this page\n",
            "Found 80 character tags on this page\n",
            "Found summaries on this page\n",
            "Found words on this page\n",
            "Found chapter on this page\n",
            "\n",
            "Total titles collected: 80\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "def scrape_titles_two_pages(driver):\n",
        "    titles = []\n",
        "    links= []\n",
        "    authors= []\n",
        "    fandom_tags= []\n",
        "    relationship_tags= []\n",
        "    character_tags= []\n",
        "    freeform_tags= []\n",
        "    summary= []\n",
        "    words= []\n",
        "    chapters= []\n",
        "    latest_view= []\n",
        "    current_page = 1\n",
        "    max_pages = 4\n",
        "\n",
        "    while current_page <= max_pages:\n",
        "        print(f\"Scraping page {current_page}\")\n",
        "\n",
        "        # Scrape current page\n",
        "        # getting titles and links\n",
        "        header_titles = driver.find_elements(By.CSS_SELECTOR, 'h4.heading a[href^=\"/works/\"]')\n",
        "        print(f\"Found {len(header_titles)} titles on this page\")\n",
        "\n",
        "        for title in header_titles:\n",
        "            titles.append(title.text)\n",
        "            links.append(title.get_attribute('href'))\n",
        "\n",
        "\n",
        "        # getting authors, fandoms tags, relationship tags, character tags\n",
        "        articles = driver.find_elements(By.CSS_SELECTOR, 'li[role=\"article\"]')\n",
        "        for article in articles:\n",
        "            #authors\n",
        "            author_elements= article.find_elements(By.CSS_SELECTOR, 'h4.heading a[rel=\"author\"]')\n",
        "            author_list= [author.text for author in author_elements]\n",
        "            if not author_list:\n",
        "              authors.append(\"Anonymous\")\n",
        "            else:\n",
        "              authors.append(\", \".join(author_list))\n",
        "\n",
        "            # fandoms\n",
        "            fandom_elements = article.find_elements(By.CSS_SELECTOR, 'h5.fandoms a')\n",
        "            fandom_list= [fandom.text for fandom in fandom_elements]\n",
        "            fandom_tags.append(\", \".join(fandom_list))\n",
        "\n",
        "            # relationship tags\n",
        "            relationship_elements= article.find_elements(By.CSS_SELECTOR, 'li.relationships a')\n",
        "            relationship_list= [relationship.text for relationship in relationship_elements]\n",
        "            relationship_tags.append(\", \".join(relationship_list))\n",
        "\n",
        "            # character tags\n",
        "            character_elements= article.find_elements(By.CSS_SELECTOR, 'li.characters a')\n",
        "            character_list= [character.text for character in character_elements]\n",
        "            character_tags.append(\", \".join(character_list))\n",
        "\n",
        "            # freeforms\n",
        "            freeform_elements= article.find_elements(By.CSS_SELECTOR, 'li.freeforms a')\n",
        "            freeform_list= [freeform.text for freeform in freeform_elements]\n",
        "            freeform_tags.append(\", \".join(freeform_list))\n",
        "\n",
        "            # summary\n",
        "            summary_elements= article.find_elements(By.CSS_SELECTOR, 'blockquote.userstuff p')\n",
        "            summary_list= [summary.text for summary in summary_elements]\n",
        "            summary.append(\"\\n\\n\".join(summary_list))\n",
        "\n",
        "            # word count\n",
        "            word_element= article.find_element(By.CSS_SELECTOR,'dd.words')\n",
        "            words.append(word_element.text)\n",
        "\n",
        "            # chapter\n",
        "            chapters_elements= article.find_element(By.CSS_SELECTOR, 'dd.chapters')\n",
        "            chapters.append(chapters_elements.text)\n",
        "\n",
        "            # view history\n",
        "            latest_view_elements= article.find_element(By.CSS_SELECTOR, 'div.user.module.group h4.viewed.heading')\n",
        "            latest_view.append(latest_view_elements.text)\n",
        "\n",
        "        print(f\"Found {len(authors)} authors on this page\")\n",
        "\n",
        "        print(f\"Found {len(fandom_tags)} fandom tags on this page\")\n",
        "\n",
        "        print(f\"Found {len(relationship_tags)} relationship tags on this page\")\n",
        "\n",
        "        print(f\"Found {len(character_tags)} character tags on this page\")\n",
        "\n",
        "        print(f\"Found {len(freeform_tags)} character tags on this page\")\n",
        "\n",
        "        print(f\"Found summaries on this page\")\n",
        "\n",
        "        print(f\"Found words on this page\")\n",
        "\n",
        "        print(f\"Found chapter on this page\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if current_page == max_pages:\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            # Add explicit wait for next button\n",
        "            next_button = WebDriverWait(driver, 10).until(\n",
        "                EC.element_to_be_clickable((By.CSS_SELECTOR, 'a[rel=\"next\"]'))\n",
        "            )\n",
        "            print(\"Found next button, attempting to click\")\n",
        "\n",
        "            # Add a small delay before clicking\n",
        "            time.sleep(2)\n",
        "\n",
        "            next_button.click()\n",
        "            print(\"Clicked next button\")\n",
        "\n",
        "            # Wait for next page to load\n",
        "            WebDriverWait(driver, 10).until(\n",
        "                EC.presence_of_element_located((By.CSS_SELECTOR, 'h4.heading'))\n",
        "            )\n",
        "            current_page += 1\n",
        "            print(f\"Successfully moved to page {current_page}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error occurred: {str(e)}\")\n",
        "            break\n",
        "\n",
        "    df= pd.DataFrame({\"Title\": titles, 'Author': authors, \"Fandom Tags\": fandom_tags, \"Relationship Tags\":relationship_tags, \"Character Tags\":character_tags,\n",
        "                      \"Freeform Tags\": freeform_tags, \"Summary\":summary, \"Chapters\": chapters, \"Words\": words, \"Latest View\": latest_view, \"Link\":links})\n",
        "\n",
        "    return df\n",
        "\n",
        "# Use the function\n",
        "all_titles = scrape_titles_two_pages(driver)\n",
        "print(f\"\\nTotal titles collected: {len(all_titles)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "jK_FkUTkoxC-"
      },
      "outputs": [],
      "source": [
        "all_titles.to_csv(\"My_AO3_data.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
